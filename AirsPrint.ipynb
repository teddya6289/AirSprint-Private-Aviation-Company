{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIRSPRINT PRIVATE AVIATION PROJECT\n",
    "\n",
    "# ETL PROCESS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "import oracledb\n",
    "import numpy as np\n",
    "import pandas.api.types as ptypes\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "\n",
    "warnings.                   filterwarnings(\"ignore\")\n",
    "\n",
    "path =                      os.path.abspath(\"C:/Users/Balli/Desktop/BI Intern Folder/BI Intern Folder\")\n",
    "\n",
    "\n",
    "CleanedDataPath =           os.path.join(path,\"CleanedDataset\")\n",
    "os.makedirs(CleanedDataPath, exist_ok=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA EXTRACTION: METHOD APPLICATION PROGRAMMING INTERFACE API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_dataextract(api_url):  \n",
    "\n",
    "    Params =    {\"from\": \"2025-01-01\",\n",
    "                    \"to\": \"2025-03-15\",\n",
    "                    \"value\": \"ALL\",\n",
    "                    \"timeZone\": \"UTC\"}\n",
    "\n",
    "    Header =    { \"content-type\": \"Application/json\",\"X-Auth-Token\":\"4y9lRGIoQtzDdPLphsO4rtzhTbLPk6Sg\" }\n",
    "\n",
    "    response = requests.get(api_url, params=Params,headers=Header)\n",
    "    if response.status_code == 200 and response.text.strip():\n",
    "                    try:\n",
    "                        FlightData = response.json()\n",
    "                        Data = pd.DataFrame(FlightData)\n",
    "                        \n",
    "                        filteredData = Data[Data[\"flightId\"].isin([79952, 79953, 79956, 79957, 79959, 79960])]\n",
    "                        selectedColumns = filteredData[[\"flightId\",\"accountId\",\"customerId\",\"accountName\",\"realAirportFrom\",\n",
    "                                            \"realAirportTo\",\"eta\",\"etd\"]]\n",
    "                        selectedColumns.loc[len(selectedColumns)] = [79958,24882,100067,\"JimJets\",None,None,None,None]\n",
    "                        selectedColumns.to_csv(os.path.join(path,  \"Flight.csv\"), index=False)\n",
    "                    except Exception as e:\n",
    "                            print(f\"Error: {e}\")\n",
    "    else:\n",
    "        print(f\"Response return error{response.status_code},{response.text}\") \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PROFILING STEP: TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def data_wrangling(df):\n",
    "# Drop empty rows         \n",
    "          df = df.dropna(axis=1, how='all')\n",
    "# Drop empty columns\n",
    "          df = df.dropna(how =\"all\")\n",
    "# Remove duplicate rows\n",
    "          df = df.drop_duplicates()\n",
    "# Replace NAN with None compatable with oracle null \n",
    "          df = df.replace({np.NaN: None})\n",
    "\n",
    "# Engineering features to data types compatable with oracle \n",
    "          for column in df.columns:\n",
    "               \n",
    "               if column in [\"Lease_Renewal_Date__c\",\"CreatedDate\", \"Lease_Renewal_Date_2__c\", \"Lease_Renewal_Date_3__c\",\"INVDATE\"]: \n",
    "                         try:\n",
    "                              df[column] = pd.to_datetime(df[column]).dt.strftime(\"%d-%b-%y\").str.upper().replace({np.NaN:None}) \n",
    "                         except:\n",
    "                              pass\n",
    "               elif column in [\"flightId\",\"Fl3xx_Id__c\",\"customerId\",\"CUSTOMER\",\"INVUNIQ\"]:\n",
    "                         df[column] = df[column].astype(str)\n",
    "               else:\n",
    "                       pass\n",
    "               if column == \"accountId\":\n",
    "                    df[column]=df[column].astype(int).astype(str)\n",
    "               if  column == \"FLIGHTID\":\n",
    "                       df[column]=df[column].apply(lambda x: str(int(x)) if pd.notna(x) and isinstance(x,float) else None)\n",
    "               if column in [\"eta\",\"etd\"]: \n",
    "                    df[column] = pd.to_datetime(df[column]).dt.strftime(\"%d-%b-%y %I:%M:%S %p\").str.upper().replace({np.NaN:None})\n",
    "               \n",
    "               df.rename(columns ={\"COMMENT\":\"COMMENTING\"}, inplace = True)\n",
    "          \n",
    "               if column in [\"Aircraft_Ownership__c\",\"Aircraft_Ownership_2__c\",\"Aircraft_Ownership_3__c\"]:\n",
    "                         df[column] = df[column].apply(lambda x: re.search(r'(\\d+)',x).group() if pd.notna(x) and\n",
    "                                                       re.search(r'(\\d+)',x) else None)\n",
    "                         df[column] = pd.to_numeric(df[column], errors=\"coerce\").fillna(0).astype(int)\n",
    "              \n",
    "               if column == \"Registration__c\" :\n",
    "                              df[\"Name\"] = df[\"Registration__c\"].str.replace(r'^\\b[A-Z]-','',regex = True)\n",
    "               if column == \"Id\" :\n",
    "                    df = df.drop_duplicates(subset = \"Id\")\n",
    "          return df\n",
    "\n",
    "def process_csv(filename):\n",
    "    file_path = os.path.join(path, filename)\n",
    "    if os.path.exists(file_path):\n",
    "          df = pd.read_csv(file_path)\n",
    "          cleaned_df = data_wrangling(df)\n",
    "          return cleaned_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CROSS-COLUMN PROFILE/TABLE PROFILING\n",
    "# PURPOSE: TO IDENTIFY KEY RELATIONSHIP BETWEEN TABLES AND INTEGRATE ACCORDING TO AIRSPRINT BUSINESS OPERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_rows(Cleaned_df):\n",
    "        AccountId_filterOpportunityTable = []\n",
    "        AccountId_filterContactTable= []\n",
    "        OpportuityId_filterAssetTable= []\n",
    "\n",
    "        if Cleaned_df.empty:\n",
    "                print(f\"File not found:\")\n",
    "        else:\n",
    "                \n",
    "                try:\n",
    "                        for column in Cleaned_df.columns:\n",
    "                                if  column == \"Id\":\n",
    "                                        AccountId_filterOpportunityTable.extend(Cleaned_df[column].drop_duplicates().tolist())\n",
    "                                elif column == \"Primary_Contact__c\":\n",
    "                                        AccountId_filterContactTable.extend(Cleaned_df[column].drop_duplicates().tolist())\n",
    "                                elif column == \"IsWon\":\n",
    "                                       OpportuityId_filterAssetTable.extend(Cleaned_df[Cleaned_df[column] == 1][\"Id\"].drop_duplicates().tolist())\n",
    "                                       \n",
    "                except Exception as e:\n",
    "                        print(F\"Error:{e}\")\n",
    "                \n",
    "                return AccountId_filterOpportunityTable,AccountId_filterContactTable,OpportuityId_filterAssetTable\n",
    "        \n",
    "            \n",
    "\n",
    "def Transform_df(df, filter_values):\n",
    "        if df.empty:\n",
    "           print(f\"File not found:\")\n",
    "        else:\n",
    "           filteredObject = pd.DataFrame()\n",
    "           try:\n",
    "\n",
    "                for column in df.columns:\n",
    "                        if  column  in [\"AccountId\",\"Id\",\"Opportunity__c\"]:\n",
    "                                if not isinstance(filter_values, list):  # Ensure filter_values is a list\n",
    "                                        filter_values = [filter_values]\n",
    "                                filteredObject = df[df[column].isin(filter_values)]\n",
    "                        if not filteredObject.empty:\n",
    "                                break\n",
    "           except Exception as e:\n",
    "                  print(f\"Error:{e}\")     \n",
    "                \n",
    "        return filteredObject\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA LOADING\n",
    "# METHOD: EXECUTE MANY INSERT INTO ORACLE DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='oracle_insert.log', \n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "def insert_into_oracledb(table_name, df):\n",
    "    db_user                 = os.environ.get('user')\n",
    "    db_connection_service   = os.environ.get('service')\n",
    "    db_password             = os.environ.get('dbpassword')\n",
    "    conn = None\n",
    "    cursor = None\n",
    "    try:\n",
    "# Connect to Oracle\n",
    "        conn    =    oracledb.connect(user=db_user, password=db_password, dsn=db_connection_service)\n",
    "        cursor  =    conn.cursor()\n",
    "        logging.info(\"Connected to Oracle Database successfully.\")\n",
    "        \n",
    "        data    =    [tuple(row) for row in df.itertuples(index=False, name=None)]\n",
    "        logging.info(f\"Prepared file with {len(df)} rows and {len(df.columns)} columns. Table Name:{table_name}\")\n",
    "\n",
    "       \n",
    "\n",
    "        placeholders =  \", \".join([f\":{i+1}\" for i in range(len(df.columns))])\n",
    "        sql =           f\"INSERT INTO {table_name} ({','.join(df.columns)}) VALUES ({placeholders})\"\n",
    "\n",
    "        try:\n",
    "            cursor.executemany(sql, data)\n",
    "            conn.commit()\n",
    "            logging.info(f\"Successfully inserted data into {table_name}.\")\n",
    "            print(f\"Data inserted into {table_name}.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during batch insert: {e}\")\n",
    "            conn.rollback()\n",
    "            logging.info(\"Rolled back the transaction.\")\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.critical(f\"Critical error connecting to Oracle or processing file: {e}\")\n",
    "        \n",
    "    finally:\n",
    "        if cursor is not None:\n",
    "            cursor.close()\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "        logging.info(\"Database connection closed.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting data into table: Account\n",
      "Inserting data into table: Opportunity\n",
      "Inserting data into table: Aircraft\n",
      "Inserting data into table: Asset\n",
      "Inserting data into table: Contact\n",
      "Inserting data into table: FlightA\n",
      "Inserting data into table: Invoice\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Extract_api_Data =api_dataextract(\"https://test.fl3xx.com/api/external/flight/flights\")\n",
    "\n",
    "\n",
    "accId_forOpp,accId_forCont,OppId_forAsset = filter_rows(process_csv(\"Account.csv\"))\n",
    "accId_forOpp1,accId_forCont1,OppId_forAsset1 = filter_rows(Transform_df(process_csv(\"Opportunity.csv\"),accId_forOpp))\n",
    "\n",
    "dataframes = {\n",
    "                        \"Account\":      process_csv(\"Account.csv\"),\n",
    "                        \"Opportunity\" : Transform_df(process_csv(\"Opportunity.csv\"),accId_forOpp),\n",
    "                        \"Aircraft\":     process_csv(\"Aircraft.csv\"),\n",
    "                        \"Asset\":        Transform_df(process_csv(\"Asset.csv\"),OppId_forAsset1),\n",
    "                        \"Contact\":      Transform_df(process_csv(\"Contact.csv\"),accId_forCont),\n",
    "                        \"FlightA\":      process_csv(\"Flight.csv\"),\n",
    "                        \"Invoice\":      process_csv(\"invoices.csv\")}\n",
    "\n",
    "# Insert all DataFrames into their respective Oracle tables\n",
    "for table_name, cleaned_df in dataframes.items():\n",
    "    print(f\"Inserting data into table: {table_name}\")\n",
    "    insert_into_oracledb(table_name, cleaned_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
